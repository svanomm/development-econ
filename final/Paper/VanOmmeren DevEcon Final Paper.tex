\documentclass[12pt]{article}
\usepackage{amssymb,amsmath,amsfonts,bbm,bm,dcolumn,booktabs,eurosym,geometry,ulem,graphicx,color,xcolor,setspace,sectsty,comment,float,caption,pdflscape,subfigure,array,hyperref,listings}
\usepackage{xurl}
\usepackage[font=bf]{caption}
\usepackage[bottom]{footmisc}

\lstset{
basicstyle=\small\ttfamily,
columns=flexible,
breaklines=true
}

\hypersetup{
    colorlinks,
    linkcolor={black},
    citecolor={blue!35!black},
    urlcolor={blue!35!black}
}
\normalem
\interfootnotelinepenalty=10000
\setcounter{tocdepth}{2}

\geometry{left=1.0in,right=1.0in,top=1.0in,bottom=1.0in}
\usepackage[style=authoryear,backend=bibtex,maxcitenames=2]{biblatex}
\addbibresource{biblio.bib}

\begin{document}
\title{Exploring Heterogeneous Responses to Text Message Development Programs: An Application of Machine Learning to \textcite{fabregas_digital_2025}}
\author{Steven VanOmmeren\thanks{\href{mailto:sevanommeren@gmail.com}{sevanommeren@gmail.com}. A complete replication package of this project is available at \url{https://github.com/svanomm/development-econ/}.}}
\date{\today}
\maketitle
\noindent
\tableofcontents
\newpage

\doublespacing
\section{Introduction}

The chief concern of development economics is in improving the lives of poor people in the poorest countries of the world. There are many ways to develop an economy; top-down approaches focus on improving the quality of formal and informal institutions in the economy to promote efficient markets, while bottom-up approaches try to equip individuals with the skills and resources they need to improve their lives. A major advancement in the theory of economic development in the 21st century is the use of experiments to guide effective policies.\footnote{See \textcite{basu_influence_2020} for a description of the explosive growth of experiments (and in particular randomized experiments) to measure causal effects of various development policies.} 

In this paper, we study a particular type of bottom-up experiment, grounded in behavioral science, which attempts to steer poor people towards using productivity-increasing technology. Such experiments have historically involved expensive in-person training, but the widespread adoption of mobile phones allows for low-cost text message interventions to be used instead. Text experiments are now being tested in a wide range of contexts, from healthcare to finance to agriculture. We study agricultural experiments in particular, which often center around convincing farmers to adopt new practices or technologies that are expected to improve profitability.

In this paper, we replicate and extend the findings of \textcite{fabregas_digital_2025}, who analyze six randomized controlled trials involving 128,000 farmers in Kenya and Rwanda, finding that text message-based agricultural extension programs modestly but significantly increase the adoption of lime and fertilizer. The authors are mostly concerned with average treatment effects, but our focus is on the heterogeneity of treatment effects across different farmer characteristics.

The key hypothesis of this paper is that development policies based in behavioral science would benefit from tailoring the programs to specific groups of people, rather than casting a wide net. In particular, we use the authors' survey data to model lime/fertilizer adoption as a complex, non-linear function of observed characteristics. We show that powerful machine learning models can model the probability of adoption better than the authors' traditional analysis, and then explain how such models could be used for policies going forward. We envision a sophisticated large-scale text program which caters the types of messages sent to each farmer based on their individual characteristics, with the hope of identifying a text program that maximizes the probability of adopting profitable technologies.

The rest of this paper is as follows: the following section reviews the relevant literature on behavioral science, the use of text messages in agricultural development, and our paper of interest. Section \ref{section:methods} describes the data preparation and modeling techniques used in this paper. Section \ref{section:results} presents the results of our models and other analyses. Section \ref{section:discussion} discusses the implications of our findings and their relation to the existing literature. Section \ref{section:conclusion} concludes.

\section{Literature Review}
\label{section:litreview}

\subsection{Behavioral Development Economics}
Results from classical economic theory typically assume that individuals make decisions rationally, with perfect foresight and complete information about the world. But studies in behavioral economics have repeatedly shown that these assumptions do not hold (even approximately) in real life. In particular, many studies in development economics have found that extremely poor people make decisions that may seem irrational or against their own self-interest,\footnote{Of course, irrational decisions are not exclusive to poor people, but a broader discussion of behavioral bias is beyond the scope of this paper.} such as not saving any money, spending excessively on alcohol and tobacco, or failing to adopt productivity-increasing technology. Experimental research in the past 20 years has shown that understanding and correcting these choices can result in increased income at the micro level, leading to economic development at the macro level.

In \textcite{banerjee_understanding_2006} Chapter 24, Esther Duflo explores potential explanations for why Kenyan farmers consistently fail to use fertilizer on their crops, despite it being cheap and profitable. Duflo explains that traditional or ``neoclassical'' explanations such as lack of access to efficient credit markets do not explain the observed behavior. While experimental evidence is inconclusive, Duflo suggests several likely psychological factors at play. For the extremely poor, a bad crop harvest could mean starvation, and so farmers may be extremely risk averse when it comes to adopting new technology.\footnote{Even if the costs involved in experimenting with new fertilizer are low, the small perceived possibility of a bad harvest could be detrimental to the farmer. Additionally, poor farmers may worry that taking on debt to finance investments could lead them to lose their land.} There is a mental cost associated with learning the new fertilizer techniques. Offering farmers the ability to pay for fertilizer using future crop harvest (instead of cash savings) was able to increase adoption rates. The takeaway is that traditional economic models are insufficient in explaining the choices of poor people, and that behavioral-inspired interventions can improve their outcomes as a development policy. 

Behavioral economics has a rich literature focused on identifying the psychological factors involved in everyday economic decision-making. Two important concepts that we review here are ``salience'' and ``nudges.'' These concepts help us understand the basis for text-based interventions in development economics, which we discuss later.

In exploring the many heuristics that people use in making decisions, \textcite{tversky_judgment_1974} identify that availability, or the relative ease with which information can be recalled, can bias a person away from rational decisions. Within the topic of availability, ``salience'' describes how ``top-of-mind'' a piece of information is. People process an enormous amount of information each day, and then they forget much of it. Events that occur more recently, or are more emotionally charged, are generally easier to remember. While this is not a particularly surprising idea, salience could explain why people make seemingly irrational decisions. Considering that extremely poor farmers often live in dangerous and dire conditions, they may put knowledge of fertilizer and other technology aside to focus on more immediate concerns. The flip side of this is that salience is an easy bias to influence: simple reminders will make a topic more salient, and thus more likely to be considered in decision-making. This is the basis for many behavioral interventions, including text messages.

\textcite{thaler_nudge_2009}'s concept of ``nudges'' are based on the observation that in some situations, making seemingly small and inexpensive changes to the choices available to a person can significantly change their decisions. A classic example of a behavioral nudge is changing the default 401(k) contribution for employees from 0 to some small amount. When the default contribution is 0, employees often do not change it, but when the default is non-zero, they tend to keep the contribution at that level. Employees can still choose to opt out of contributions, but they tend not to, which results in better outcomes for the employees.

\textcite{halpern_nudging_2016} review several examples of successful nudges in policy settings. For example, in the United Kingdom, adding the line ``most people pay their tax on time'' in letters to taxpayers was enough to substantially reduce the amount of late tax filings. Incorporating simple commitment devices like asking job seekers when they will be looking for jobs next week was enough to reduce the person-days on welfare by 5 to 10 million, saving the U.K. government as much as \$150 million per year. In summary, the authors highlight that appropriately-designed policy changes based on nudges can bring significant benefits to an economy, provided that they are grounded in good science and are evaluated carefully.

\subsection{Text Experiments}
One promising avenue of nudge policies in development economics is the use of text messages to influence behavior. Cellphone adoption has increased dramatically in the past 20 years, even in the poorest communities of the world. Text messages have very low marginal cost, making them an easy program to justify for a developing economy, and a highly scalable one. In particular, text messages remove the need for in-person visits, which require trained staff and are difficult to scale. Finally, large-scale text message campaigns can be easily randomized, allowing for experimentation, causal inference, and fast iterative improvements. Below, we review the rather mixed results of the literature on text message campaigns in agricultural development economics.

\textcite{fafchamps_impact_2012} represent the earlier end of the literature on text interventions. The authors perform a randomized control trial (RCT) on 1000 farmers in India, in which farmers were offered a subscription to Reuters Market Light, an agricultural information service. The authors estimate an instrumental variables (IV) regression to control for endogenous selection into the subscription service,\footnote{While the experiment randomly assigned the offer of a subscription, not all farmers chose to subscribe. This was a serious issue, as only 59\% of farmers accepted the offer. Further, some farmers subscribed to the program even without the free offer, though this was a much less pervasive issue.} finding little to no benefit from the subscription. Prices obtained by the farmers do not increase after receiving the subscription. Additional models of costs, net prices, revenues, and profits all show no significant differences between the treatment and control groups. It is important to note that the subscription was expected to benefit farmers only by providing more accurate pricing information, not in teaching or reminding them of new agricultural techniques that are known to be more profitable. As we will see in \textcite{fabregas_digital_2025}, the latter type of text message campaign is likely to be more successful.

\textcite{aker_promise_2016} attempt to unify research from disparate fields on the adoption of information and communication technologies (ICTs) in the agricultural sector. The authors explain that there is likely significant heterogeneity in the effectiveness of ICTs in improving development, using gender as an example. Further, economic studies based solely on economic theory may miss the sociological and cultural factors that influence the adoption of ICTs: ``issues such as trust, information quality and the role of gender, caste and ethnicity'' all come into play with regards to the acceptance of ICTs. This makes it difficult to identify the effectiveness of ICT campaigns such as text messages without careful experimentation. The authors review several text-based studies with mixed results. For example, \textcite{casaburi_harnessing_2019} found a positive effect of text messages on sugar cane production in Kenya, while \textcite{casaburi_management_2016} found no effect when applying the experiment to a different group of farmers.\footnote{Note that despite the paper dates, \textcite{casaburi_harnessing_2019} data were collected prior to the data used in \textcite{casaburi_management_2016}.}

\textcite{carrion-yaguana_promoting_2020} conduct a randomized control trial in the Tungurahua and Bolivar provinces of Ecuador with a sample size of 292 blackberry farmers. Farmers in the treatment group received a series of text messages reminding them of recommended practices to improve their production (such as applying fertilizer at the right time, pruning branches, and disinfecting tools between uses). Importantly, the messages were sent based on the harvest schedule of blackberry production, so that each text would be relevant and timely. In other words, the recommended practices would be \textit{salient} for the farmers at the right time. Another notable aspect is that the farmers had an average of 10 years of relevant experience going into the study, so they already knew the details of blackberry production, though not necessarily about modern agronomic research. The authors then use a multivariate Poisson regression to estimate whether the text messages increased the expected number of policies adopted by the farmers, controlling for demographic information such as age, education, and gender. They find mixed results: certain types of policies are adopted more frequently by the treatment group, but others have no significant effect. Further, the authors find heterogeneous effects: less-educated farmers are more likely to be affected by the text messages, while well-educated farmers are not affected. Overall, the results are promising that text messages could provide short-term productivity gains to farmers with mobile phones, but there is clearly a need for larger sample sizes to understand the relatively small effects involved.\footnote{Another weakness of the study is that the outcome is just the adoption of recommended practices, not actual production. Collecting data on subsequent production would have been much more expensive and time consuming. Thus, the underlying assumption is that adopting the recommended practices should increase production on average.}

\subsection{\textcite{fabregas_digital_2025}}
\textcite{fabregas_digital_2025} offers an excellent example of the type of rigorous analysis that is necessary to improve the adoption of text campaigns for economic development. The authors analyze data from six large-scale experiments conducted in Kenya and Rwanda from 2015 to 2019, with a combined sample size of 128,000 farmers. These farmers live in areas with acidic soil that benefits from the application of lime and fertilizer. Both materials are cheap and available, and are very likely to provide a profit to the farmers in these studies,\footnote{The studies were conducted in areas where soil is highly acidic, which is bad for production. Applying lime decreases the acidity in the soil, nearly guaranteeing a higher crop yield. Applying fertilizer is also nearly guaranteed to increase yield.} yet they have low adoption rates.\footnote{The authors found baseline adoption rates of between 6 and 12 percent for agricultural lime, depending on the sample.} Improving the adoption of lime and fertilizer would provide a small but significant boost to low-income farmers, helping to prop up the local economies. The authors study a relatively simple question: can text messages improve the adoption rates of lime and fertilizer?

The outcome of interest in this analysis is a binary variable indicating whether the farmer adopted the recommended practices of applying lime and fertilizer (a value of 1), or did not adopt them (a value of 0). The authors use two statistical frameworks for analyzing how the text messages affect the likelihood of adoption: ordinary least squares (OLS) regression and logistic regression. While OLS regression assumes that the outcome variable is continuous and unbounded, it is not uncommon for researchers to use OLS regression on binary outcomes, as OLS can be easier to interpret and understand. Conversely, logistic regression is designed for binary outcomes, and so it is likely the more appropriate model for this analysis. Logistic regressions estimate coefficients for each control variable included in the model. In this case, \textcite{fabregas_digital_2025} report odds ratios, which are interpreted as the relative likelihood of adopting lime/fertilizer. Odds ratios are relative values; when interpreting the treatment effect, a value of 1.2 means that the treatment group is 1.2 times (20\% more) likely to adopt the recommended practices than the control group.

The authors conducted a comprehensive evaluation of the six text message studies, analyzing the studies individually as well as combining them with meta-analysis methodology to assess impacts on farmer adoption of recommended practices. The meta-analysis methodology is a powerful way for the authors to combine the sample sizes of each study to gain statistical precision. In their main results, the authors report that farmers who received the text messages (the treatment group) are 19\% more likely to adopt lime, and 27\% more likely to adopt fertilizer, relative to those who did not receive the text messages (the control group). Both results are statistically significant at the 5\% level. However, their results also show that the individual studies exhibit heterogeneity, with some studies finding no statistically significant treatment effects. Combining the lime and fertilizer studies yields an overall effect of 22\%.

After reporting the statistical models, the authors discuss the cost effectiveness of the text message interventions. The marginal cost of sending one text message is reportedly \$0.01 in these regions, but could be lowered to \$0.001 on a larger scale. Putting that into context, sending 5 text messages to 128,000 farmers (the combined sample size) at a rate of \$0.001 per message would cost only \$640. In contrast, in-person training events cost several dollars per person, per event. Training 128,000 farmers using the authors' estimate of \$9 per person would cost \$1,152,000, or 1,800 times as expensive as a text message program. The authors estimate that the benefit-cost ratio of a large-scale text message program could be as much as 18:1. Once a text message campaign program is established, the difference between messaging 5,000 farmers and 500,000 farmers is very minimal compared to in-person campaigns.

The analysis of \textcite{fabregas_digital_2025} addresses many of the weaknesses in earlier studies mentioned above. For example, \textcite{fafchamps_impact_2012} used a sample size of 1000 farmers, which is likely insufficient to detect weak effect sizes. \textcite{fabregas_digital_2025} instead combine the results of six studies to get a sample that is orders of magnitude larger. \textcite{casaburi_harnessing_2019} and \textcite{casaburi_management_2016} found conflicting results when studying separate samples; this may not necessarily be a weakness, but \textcite{fabregas_digital_2025} addresses the problem of multiple samples by studying six different samples that vary over time and geography. Finally, while \textcite{carrion-yaguana_promoting_2020} measure the adoption of recommended practices by a self-reported survey, \textcite{fabregas_digital_2025} address the potential for bias by studying administrative data that confirms whether farmers actually purchased the recommended inputs, rather than simply saying they did.

While the purpose of the \textcite{fabregas_digital_2025} analysis was to determine aggregate effectiveness of text messages for large-scale policy recommendations, the authors also perform a few sensitivity analyses to explore potential heterogeneous responses to the text messages. The authors run separate regressions for different subpopulations of their data, such as females only, people with primary education only, and young people only. While there are some differences in the treatment effect measured by each regression, they ``find no evidence of a statistically significant differential program effect by these characteristics,'' even when pooling the studies to increase sample size. 

However, there are a few weaknesses of the authors' heterogeneity analysis. First, the authors only study heterogeneous effects separately for each demographic variable; they do not attempt to interact the controls with each other. Second, the authors only tested logistic and OLS regressions. It is possible that the relationship between observed demographics and treatment effects are more complex than these basic models can capture. Based on the discussion in \textcite{aker_promise_2016}, it is surprising for \textcite{fabregas_digital_2025} to find no indication of heterogeneous effects. The purpose of our analysis to further explore the authors' data to see if heterogeneity exists in a more nuanced way than the authors investigated.

\section{Methods}
\label{section:methods}

\subsection{Data Preparation}
\textcite{fabregas_digital_2025} graciously provide a detailed Online Appendix and replication package for their results, which includes the data used in their regression analyses.\footnote{\url{https://www.openicpsr.org/openicpsr/project/186241/version/V1/view}.} We began by running all of their Stata code to build their regression datasets, as well as replicating their regression results.

Additionally, we sourced supplementary data from the World Bank Group. The World Development Indicators (WDI) database provides a variety of country-level statistics by country and year.\footnote{\url{https://datacatalog.worldbank.org/search/dataset/0037712}.} We selected the following variables for our analysis:
\begin{itemize}
    \singlespacing
    \item Mobile cellular subscriptions (per 100 people)
    \item Individuals using the Internet (\% of population)
    \item Adjusted net national income per capita (constant 2015 US\$)
    \item Literacy rate, adult total (\% of people ages 15 and above)
\end{itemize}
After filtering the data to these variables, we selected the following countries: Kenya, Rwanda, Ecuador, India, and United States. This list includes the countries mentioned in the text experiments discussed above, as well as the United States as a reference developed country. We selected data from 2010 to 2019 to analyze trends over time; this period includes the time during which the \textcite{fabregas_digital_2025} experiments were conducted.

\subsection{Modeling}
We specifically study the models underlying Table E2 in the \textcite{fabregas_digital_2025} Online Appendix. This table reports the results of 24 regressions: 6 logit and 6 OLS models, each of which is run on both the lime and the fertilizer recommendations. These are ``pooled'' models that combine the data from all the experiments that include the relevant controls. Because OLS is not ideal for studying binary outcomes, we only report the logit models. Each model uses the following specification:
\begin{equation}
    \mathbbm{1}[\text{Followed Recommendations}_i] = \alpha \cdot \text{Treated}_i + \beta X_i + \gamma \cdot (\text{Treated}_i \times X_i) + \epsilon_i,
\end{equation}
where Treated is an indicator for whether farmer $i$ was in the treatment group (received texts), $X$ is a demographic variable of interest, and $(\text{Treated}_i \times X_i)$ measures the interaction between the treatment and the demographic variable. $\epsilon$ is the error term. The following 6 variables are used for $X$:
\begin{itemize}
    \singlespacing
    \item Female
    \item Primary: whether respondent completed primary school
    \item Large Farm: more than 1.5 acres of land
    \item Young: under 40 years old
    \item Used Input: whether the respondent had previously used the input
    \item Heard Input: whether the respondent had previous knowledge of the input or was aware of it
\end{itemize}

The authors originally reported only the regression coefficients, the sample size, and the mean outcome for the Control group. They did not report any measures of model fit. We modify their code to report two measures of classification accuracy: the balanced accuracy statistic and the area under the receiver operating characteristic curve (AUROC). The balanced accuracy statistic is defined as the average of the true positive rate and true negative rate, and is a good measure of model fit for binary outcomes on unbalanced data. The AUROC is a measure of how well the model can distinguish between the two classes at various classification thresholds.

An additional important note is that not all demographics were collected in each experiment, so the sample size differs among the models. This is likely why the authors did not try to combine demographics into a single model. Regardless, we report additional logit models that incorporate multiple demographics and their interactions to study more complex heterogeneity, although some of our models suffer from small sample sizes.

Next, we implement a machine learning technique called LightGBM. LightGBM is a histogram-based gradient boosting tree model created by \textcite{ke_lightgbm_2017}, created as an extension to the popular XGBoost technique. The model works by iteratively splitting the data into ``branches'' of if-then statements that best fit the outcome variable. By repeatedly fitting new trees onto the residuals of existing trees, the model is able to learn complex relationships that can approximate any function. LightGBM is widely known as a versatile machine learning technique that works remarkably well with tabular data. An important aspect of LightGBM for our purposes is that it natively supports missing values by treating them as a distinct value in the splitting procedure. 

\section{Results and Analysis}
\label{section:results}
\subsection{Summary Analysis}

\subsection{Correlation Analysis}

\subsection{Models}

\subsection{Model Predictions}
All results in this section use the LightGBM model with the highest $R^2$ from the table above, unless otherwise specified.


\subsubsection{Sentiment Contribution}
\section{Discussion}
\label{section:discussion}

\section{Conclusion}
\label{section:conclusion}

\newpage
\printbibliography
\newpage

\section{Appendix}

\end{document}